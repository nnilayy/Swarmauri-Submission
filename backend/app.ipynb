{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.layout import LAParams\n",
    "from dotenv import load_dotenv\n",
    "from swarmauri.documents.concrete.Document import Document\n",
    "from swarmauri.conversations.concrete.Conversation import Conversation\n",
    "from swarmauri.chunkers.concrete.SentenceChunker import SentenceChunker\n",
    "from swarmauri.vector_stores.concrete.TfidfVectorStore import TfidfVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key from environment variables\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Check if the API key is set\n",
    "if not API_KEY:\n",
    "    print(\"API key is not set. Please set the GROQ_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chunker\n",
    "vector_store = TfidfVectorStore()\n",
    "pdf_path = \"Resume_CV-Nilay Kumar.pdf\"\n",
    "formatted_text = extract_text_from_pdf(pdf_path)\n",
    "chunks = chunk_text(formatted_text, chunk_size=300, overlap=150)\n",
    "documents = [Document(content=chunk) for chunk in chunks]\n",
    "vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(name=None, id='f2b5e2a9-e6bb-4fa9-be7a-638e2514caf4', members=[], owner=None, host=None, resource='Document', version='0.1.0', type='Document', content='nnilayy.work@gmail.com | LinkedIn | github.com/nnilayy | Certifications | +91-6377778313 Nilay Kumar SUMMARY Passionate Software Engineer with expertise in Full-Stack Development and Machine Learning, with 1+ years of industrial experi- ence at SONY. Skilled in building and deploying scalable web applications, integrating intuitive front-end designs with efficient and secure back-end systems. Research experience spans ML projects under prestigious universities, with a focus on EDA, data prepro- cessing, and developing practical ML solutions. Proficient in designing APIs, database management, and leveraging cloud platforms for application deployment. Committed to continuous learning and adopting best practices in Full-Stack Development and Software Engineering. SKILLS (cid:35) Languages: Python, C, C++, C#, Java ML, DL & Data Science: TensorFlow, PyTorch, Keras, Scikit-Learn, XGBoost, LightGBM, ONNX, IMB-Learn, OpenCV, (cid:35) Pandas, NumPy, Seaborn, Matplotlib, NLTK, Spacy, MATLAB, Regex, SQL Web-Development: HTML, Tailwind CSS, JavaScript, ReactJS, NodeJS, ExpressJS, FastAPI, Django, MongoDB, NoSQL (cid:35) Databases DevOps, OS & Automation: Git, CICD, Docker, Kubernetes, AWS, Terraform, Jenkins, Linux/Unix (cid:35) WORK EXPERIENCE SONY | ML Research Intern | India/Japan (cid:35) and Mechanical Teams. September 2022 – September 2023 Spearheaded the team as a machine learning research lead and collaborated in a cross-functional team with the Electronics, GUI, Engineered 8-bit Super Quantized and Pruned Classification, Object Detection, and Segmentation models for detecting cracks (cid:35) and steel defects for Spresense microcontroller. Fine-tuned Diffusion based generative models for acquiring synthetic images for expanding and enhancing the quality of the (cid:35) dataset. Developed a Polygon Coordinates to Bitmask Image conversion script, streamlining segmentation masks and reducing the man- ual annotation workload by 47%. Optimized camera capture script rate from 560 ms/image to 30 ms/image (18x Faster). Implemented two-way communication via web sockets on a server, where ESP32 transmits Base64-encoded image strings, IMU coordinates, and model predictions as JSON. IIT MADRAS | Research Intern | Chennai, India January', metadata={}, embedding=None),\n",
       " Document(name=None, id='39216f4a-1a28-4e06-a40a-99c21c1dff80', members=[], owner=None, host=None, resource='Document', version='0.1.0', type='Document', content='Docker, Kubernetes, AWS, Terraform, Jenkins, Linux/Unix (cid:35) WORK EXPERIENCE SONY | ML Research Intern | India/Japan (cid:35) and Mechanical Teams. September 2022 – September 2023 Spearheaded the team as a machine learning research lead and collaborated in a cross-functional team with the Electronics, GUI, Engineered 8-bit Super Quantized and Pruned Classification, Object Detection, and Segmentation models for detecting cracks (cid:35) and steel defects for Spresense microcontroller. Fine-tuned Diffusion based generative models for acquiring synthetic images for expanding and enhancing the quality of the (cid:35) dataset. Developed a Polygon Coordinates to Bitmask Image conversion script, streamlining segmentation masks and reducing the man- ual annotation workload by 47%. Optimized camera capture script rate from 560 ms/image to 30 ms/image (18x Faster). Implemented two-way communication via web sockets on a server, where ESP32 transmits Base64-encoded image strings, IMU coordinates, and model predictions as JSON. IIT MADRAS | Research Intern | Chennai, India January 2024 – July 2024 Curated and annotated a comprehensive dataset of 6000 images from major Ship Datasets like VOID, SGF, VAIS, MARVEL, MODD, MarDCT. (cid:35) Devised and optimized, scalable and robust Object Detection, Localization, and Tracking models for determining precise loca- tion of objects, accurate distance measurement, and effective determination of velocity and orientation of target ships through Stereo Camera Setup. Compared Stereo Camera System with LIDAR for distance measurement, with the Stereo system achieving a higher level of ac- curacy for farther distances by 10%. Deployed the Detection, Tracking, and Localization model on a miniaturized ship and conducted testing using a wave simulator (cid:35) basin. BINGHAMTON UNIVERSITY | ML Research Fellow | New York City, USA January 2023 – May 2023 Collaborated with a cross-functional team of doctors and researchers to compile a dataset of 4,560 patients diagnosed with Atrial Fibrillation. ratio of the dataset. Employed Wave Preprocessing and', metadata={}, embedding=None),\n",
       " Document(name=None, id='a3efec77-05ca-4b4f-96bd-6e0b7404cf0d', members=[], owner=None, host=None, resource='Document', version='0.1.0', type='Document', content='2024 – July 2024 Curated and annotated a comprehensive dataset of 6000 images from major Ship Datasets like VOID, SGF, VAIS, MARVEL, MODD, MarDCT. (cid:35) Devised and optimized, scalable and robust Object Detection, Localization, and Tracking models for determining precise loca- tion of objects, accurate distance measurement, and effective determination of velocity and orientation of target ships through Stereo Camera Setup. Compared Stereo Camera System with LIDAR for distance measurement, with the Stereo system achieving a higher level of ac- curacy for farther distances by 10%. Deployed the Detection, Tracking, and Localization model on a miniaturized ship and conducted testing using a wave simulator (cid:35) basin. BINGHAMTON UNIVERSITY | ML Research Fellow | New York City, USA January 2023 – May 2023 Collaborated with a cross-functional team of doctors and researchers to compile a dataset of 4,560 patients diagnosed with Atrial Fibrillation. ratio of the dataset. Employed Wave Preprocessing and Denoising techniques to denoise ECG signals, resulting in 25% improvement in signal to noise Trained and evaluated CNN, RNN and LSTM based models for detecting Atrial Fibrillation, achieving an accuracy rate of 92% (cid:35) for CNN and 88% for LSTM models. Setup IOT Sensors-AD8232 and ESP32 to capture real-time ECG data of a patient’s heart for real-time prediction of Atrial (cid:35) fibrillation. PROJECTS & RESEARCH Customer Relations Management & Analytics Web-App [GitHub] [Site]: Engineered a full-stack CRM system using Re- (cid:35) act.js, TypeScript, and GraphQL with comprehensive authentication and real-time features. Implemented an interactive Kanban board with live updates using efficient GraphQL queries. Babel Bridge [GitHub]: Developed a Full-Stack MERN web app and fine-tuned Large Language Models for the task of Auto- (cid:35) matic Speech Recognition to transcribe Native Indian Language audio into various Foreign Language texts. Collected raw audio datasets and implemented a streamlined training pipeline, resulting in a', metadata={}, embedding=None),\n",
       " Document(name=None, id='04a08e6d-c365-4161-991f-8f9b23fe6bbc', members=[], owner=None, host=None, resource='Document', version='0.1.0', type='Document', content='Denoising techniques to denoise ECG signals, resulting in 25% improvement in signal to noise Trained and evaluated CNN, RNN and LSTM based models for detecting Atrial Fibrillation, achieving an accuracy rate of 92% (cid:35) for CNN and 88% for LSTM models. Setup IOT Sensors-AD8232 and ESP32 to capture real-time ECG data of a patient’s heart for real-time prediction of Atrial (cid:35) fibrillation. PROJECTS & RESEARCH Customer Relations Management & Analytics Web-App [GitHub] [Site]: Engineered a full-stack CRM system using Re- (cid:35) act.js, TypeScript, and GraphQL with comprehensive authentication and real-time features. Implemented an interactive Kanban board with live updates using efficient GraphQL queries. Babel Bridge [GitHub]: Developed a Full-Stack MERN web app and fine-tuned Large Language Models for the task of Auto- (cid:35) matic Speech Recognition to transcribe Native Indian Language audio into various Foreign Language texts. Collected raw audio datasets and implemented a streamlined training pipeline, resulting in a reduction of Word Error Rate (WER) from 12% to 10%. Movie Recommender Engine [GitHub] [Site]: Engineered a Full-Stack, Cosine-Similarity Based Movie Recommendation web (cid:35) app, designed an NLP pipeline for data preprocessing, and utilized Flask as the backend to access APIs, enabling invocation of the recommender function and dynamic rendering of movie placard. EDUCATION SRM INSTITUTE OF SCIENCE AND TECHNOLOGY | Chennai, India Bachelor of Technology in Computer Science and Engineering W/S AI & ML 2021-2025 CGPA: 9.21 (cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35)', metadata={}, embedding=None),\n",
       " Document(name=None, id='613c759d-1f88-4b1a-9af2-4a63a25f298b', members=[], owner=None, host=None, resource='Document', version='0.1.0', type='Document', content='reduction of Word Error Rate (WER) from 12% to 10%. Movie Recommender Engine [GitHub] [Site]: Engineered a Full-Stack, Cosine-Similarity Based Movie Recommendation web (cid:35) app, designed an NLP pipeline for data preprocessing, and utilized Flask as the backend to access APIs, enabling invocation of the recommender function and dynamic rendering of movie placard. EDUCATION SRM INSTITUTE OF SCIENCE AND TECHNOLOGY | Chennai, India Bachelor of Technology in Computer Science and Engineering W/S AI & ML 2021-2025 CGPA: 9.21 (cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35) (cid:35)', metadata={}, embedding=None)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroqModel(name='llama-3.1-70b-versatile', id='68200eb5-4d23-4d9e-8126-f7c426ec44e5', members=[], owner=None, host=None, resource='LLM', version='0.1.0', type='GroqModel', allowed_models=['gemma-7b-it', 'gemma2-9b-it', 'llama-3.1-70b-versatile', 'llama-3.1-8b-instant', 'llama-3.2-11b-text-preview', 'llama-3.2-1b-preview', 'llama-3.2-3b-preview', 'llama-3.2-90b-text-preview', 'llama-guard-3-8b', 'llama3-70b-8192', 'llama3-8b-8192', 'llama3-groq-70b-8192-tool-use-preview', 'llama3-groq-8b-8192-tool-use-preview', 'llava-v1.5-7b-4096-preview', 'mixtral-8x7b-32768'], api_key='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')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from swarmauri.llms.concrete.GroqModel import GroqModel as LLM\n",
    "llm = LLM(api_key=API_KEY)\n",
    "allowed_models = get_allowed_models(llm)\n",
    "llm.name = allowed_models[2]\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swarmauri.conversations.concrete.MaxSystemContextConversation import MaxSystemContextConversation\n",
    "from swarmauri.messages.concrete.SystemMessage import SystemMessage\n",
    "from swarmauri.messages.concrete.HumanMessage import HumanMessage\n",
    "from swarmauri.agents.concrete.RagAgent import RagAgent\n",
    "\n",
    "# Create a new system context for the RAG Agent\n",
    "rag_system_context = \"You are an assistant that provides answers to the user. You utilize the details below:\"\n",
    "rag_conversation = MaxSystemContextConversation(\n",
    "    system_context=SystemMessage(content=rag_system_context), max_size=50\n",
    ")\n",
    "\n",
    "rag_agent = RagAgent(\n",
    "    llm=llm,\n",
    "    conversation=rag_conversation,\n",
    "    system_context=rag_system_context,\n",
    "    vector_store=vector_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their personal email link is nnilayy.work@gmail.com\n"
     ]
    }
   ],
   "source": [
    "query = \"What is their personal email link?\"\n",
    "response = rag_agent.exec(query)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
